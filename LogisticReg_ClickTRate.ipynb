{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ML Logo](http://spark-mooc.github.io/web-assets/images/CS190.1x_Banner_300.png)\n",
    "# **Click-Through Rate Prediction Lab**\n",
    "This lab covers the steps for creating a click-through rate (CTR) prediction pipeline.  You will work with the [Criteo Labs](http://labs.criteo.com/) dataset that was used for a recent [Kaggle competition](https://www.kaggle.com/c/criteo-display-ad-challenge).\n",
    "\n",
    "The material structure is essentially from the online course [BerkeleyX: CS190.1x Scalable Machine Learning](https://courses.edx.org/courses/BerkeleyX/CS190.1x/1T2015/info), in which we will use Spark and MLlib to perform logistic regression. To make the note more concise, however, I cut some contents such as tutorial introduction on **SparseVector**. Meanwhile, we will also examine other classifier: Naive Bayes, and compare it with the logistic regression. We find that logistic regression has slightly better performance than Naive Bayes.\n",
    "\n",
    "#### ** This lab will cover: **\n",
    "+  **Sec. 1: Featurize categorical data using one-hot-encoding (OHE)**\n",
    "  + ** Sec. 1.1: One-hot-encoding**\n",
    "  + ** Sec. 1.2: Define an OHE function**\n",
    "+  **Sec. 2: Construct an OHE dictionary**\n",
    "  + **Sec. 2.1: Pair RDD of (featureID, category) in the toy example**\n",
    "  + **Sec. 2.2: OHE Dictionary from distinct features**\n",
    "  + **Sec. 2.3: Automated creation of an OHE dictionary**\n",
    "+  **Sec. 3: Parse CTR data and generate OHE features**\n",
    "  + **Sec. 3.1: Parse data and splitting into training, validation and test sets**\n",
    "  + **Sec. 3.2: Determine the number of OHE features**\n",
    "  + **Sec. 3.3: Create an OHE dictionary from the dataset**\n",
    "  + **Sec. 3.4: Using LabeledPoint to store label and OHE features**\n",
    "  + **Sec. 3.5: Handling unseen features**\n",
    "+   **Sec. 4: CTR prediction and logloss evaluation**\n",
    "  + **Sec. 4.1: Logistic regression**\n",
    "  + **Sec. 4.2: Define Log loss**\n",
    "  + **Sec. 4.3: Log loss for the baseline model**\n",
    "  + **Sec. 4.4: Predicted probability**\n",
    "  + **Sec. 4.5: Evaluate the model**\n",
    "  + **Sec. 4.6: Validation log loss**\n",
    "  + **Sec. 4.7: Grid Search**\n",
    "  + **Sec. 4.8: ROC curve**\n",
    "+   **Sec. 5: Reduce feature dimension via feature hashing**\n",
    "  + **Sec. 5.1: Hash function **\n",
    "  + **Sec. 5.2: Sparsity**\n",
    "  + **Sec. 5.3: Logistic model with hashed features **\n",
    "  + **Sec. 5.4: Evaluate on the test set**\n",
    "  + **Sec. 5.5: Performance comparison using OHE and Hash feature reps**\n",
    "+   **Sec. 6: Other Classifiers**\n",
    "  + **Sec. 6.1: Naive Bayes Classifier**\n",
    "  + **Sec. 6.2: Decision Trees model (not working)**\n",
    " \n",
    "Note that, for reference, you can look up the details of the relevant Spark methods in [Spark's Python API](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD) and the relevant NumPy methods in the [NumPy Reference](http://docs.scipy.org/doc/numpy/reference/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labVersion = 'cs190_week4_v_1_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1382</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>181</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>f54016b9</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>07b5194c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>c5c50484</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>9727dd16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>b04e4670</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>60f6221e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>43f13e8b</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>731c3655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>767</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>245</td>\n",
       "      <td>...</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>3412118d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e587c466</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>74ef3502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6b3a5ca6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>9117a34a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>26b3c7a7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21c9516a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>b34f3128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1    2   3   4     5   6   7   8    9     ...           30        31  \\\n",
       "0   0   1    1   5   0  1382   4  15   2  181    ...     e5ba7672  f54016b9   \n",
       "1   0   2    0  44   1   102   8   2   2    4    ...     07c540c4  b04e4670   \n",
       "2   0   2    0   1  14   767  89   4   2  245    ...     8efede7f  3412118d   \n",
       "3   0 NaN  893 NaN NaN  4392 NaN   0   0    0    ...     1e88c74f  74ef3502   \n",
       "4   0   3   -1 NaN   0     2   0   3   0    0    ...     1e88c74f  26b3c7a7   \n",
       "\n",
       "         32        33        34        35        36        37        38  \\\n",
       "0  21ddcdc9  b1252a9d  07b5194c       NaN  3a171ecb  c5c50484  e8b83407   \n",
       "1  21ddcdc9  5840adea  60f6221e       NaN  3a171ecb  43f13e8b  e8b83407   \n",
       "2       NaN       NaN  e587c466  ad3062eb  3a171ecb  3b183c5c       NaN   \n",
       "3       NaN       NaN  6b3a5ca6       NaN  3a171ecb  9117a34a       NaN   \n",
       "4       NaN       NaN  21c9516a       NaN  32c7478e  b34f3128       NaN   \n",
       "\n",
       "         39  \n",
       "0  9727dd16  \n",
       "1  731c3655  \n",
       "2       NaN  \n",
       "3       NaN  \n",
       "4       NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_table('dac_sample.txt', header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 40)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Part 1: Featurize categorical data using one-hot-encoding **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 1.1: One-hot-encoding **\n",
    "We would like to develop code to convert categorical features to numerical ones, and to build intuition, we will work with a sample unlabeled dataset with three data points, with each data point representing an animal. The first feature indicates the type of animal (bear, cat, mouse); the second feature describes the animal's color (black, tabby); and the third (optional) feature describes what the animal eats (mouse, salmon).\n",
    "\n",
    "In a one-hot-encoding (OHE) scheme, we want to represent each tuple of `(featureID, category)` via its own binary feature.  We can do this in Python by creating a dictionary that maps each tuple to a distinct integer, where the integer corresponds to a binary feature. To start, manually enter the entries in the OHE dictionary associated with the sample dataset by mapping the tuples to consecutive integers starting from zero,  ordering the tuples first by featureID and next by category.\n",
    "\n",
    "Later in this lab, we'll use OHE dictionaries to transform data points into compact lists of features that can be used in machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1.1a) OHE for a toy example**\n",
    "\n",
    "Suppose now we have a toy dataset. There are three observations: sampleOne, sampleTwo and sampleThree. Each one then has three features: '0' denotes 'animal type', '1' 'color pattern', '2' 'food the animal eats', as follows. We prepare it as a RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "# Data for manual OHE\n",
    "# Note: the first data point does not include any value for the optional third feature\n",
    "sampleOne = [(0, 'mouse'), (1, 'black')]\n",
    "sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
    "sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]\n",
    "sampleDataRDD = sc.parallelize([sampleOne, sampleTwo, sampleThree])\n",
    "print type(sampleDataRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleOHEDictManual = {}\n",
    "sampleOHEDictManual[(0,'bear')] = 0\n",
    "sampleOHEDictManual[(0,'cat')] =  1\n",
    "sampleOHEDictManual[(0,'mouse')] = 2\n",
    "sampleOHEDictManual[(1, 'black')] = 3\n",
    "sampleOHEDictManual[(1, 'tabby')] = 4\n",
    "sampleOHEDictManual[(2, 'mouse')] = 5\n",
    "sampleOHEDictManual[(2, 'salmon')] = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(2, 'mouse'): 5, (0, 'cat'): 1, (0, 'bear'): 0, (2, 'salmon'): 6, (1, 'tabby'): 4, (1, 'black'): 3, (0, 'mouse'): 2}\n"
     ]
    }
   ],
   "source": [
    "print sampleOHEDictManual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **DenseVector rep**, the features of the toy example can be denoted as (featuredID, category). Like:\n",
    "+ (0, 'bear') = [1,0,0,0,0,0,0]\n",
    "+ (0, 'cat') = [0,1,0,0,0,0,0]  \n",
    "+ (0, 'mouse') = [0,0,1,0,...]   ....\n",
    "+ (2, 'salmon') = [0,0,.....0,1]\n",
    "\n",
    "Therefore the OHE features of these observations are represented as \n",
    "+ **sampleOne = [(0, 'mouse'), (1, 'black')]= [0,0,1,1,0,0,0,0]**\n",
    "+ **sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')] = [0,1,0,0,1,1,0]**\n",
    "+ **sampleThree = [(0, 'bear'), (1, 'black'), (2, 'salmon')] = [1,0,0,1,0,0,1]**\n",
    "\n",
    "In other words, this converts to **sampleOne: x=(x2=1,x3=1; others=0)**; **sampleTwo: x=(x1=1, x4=1, x5=1; others=0)**; **sampleThree: x=(x0=1, x3=1, x6=1; others=0)**. The OEH feature vector x is 7-dimensional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (1.1b) Sparse vector representation **\n",
    "Data points can typically be represented with a small number of non-zero OHE features relative to the total number of features that occur in the dataset.  By leveraging this sparsity and using sparse vector representations of OHE data, we can reduce storage and computational burdens.  Below are a few sample vectors represented as dense numpy arrays.  Use [SparseVector](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.SparseVector) to represent them in a sparse fashion, and verify that both the sparse and dense representations yield the same results when computing [dot products](http://en.wikipedia.org/wiki/Dot_product) (we will later use MLlib to train classifiers via gradient descent, and MLlib will need to compute dot products between SparseVectors and dense parameter vectors).\n",
    "\n",
    "Use `SparseVector(size, *args)` to create a new sparse vector where size is the length of the vector and args is either a dictionary, a list of (index, value) pairs, or two separate arrays of indices and values (sorted by index).  You'll need to create a sparse vector representation of each dense vector `aDense` and `bDense`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg import SparseVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the **SparseVector** rep, the vectors can have addition, minus, dot product operation with normal vectors etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,[1,3],[3.0,4.0])\n",
      "(4,[2],[1.0])\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "a = SparseVector(4, [1, 3], [3.0, 4.0])  ## a= [0,3,0,4]\n",
    "print a\n",
    "b = SparseVector(4, [2], [1.0])          ## b= [0,0,1,0]\n",
    "print b\n",
    "print a.dot(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.3\n",
      "7.3\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "aDense = np.array([0., 3., 0., 4.])\n",
    "aSparse = SparseVector(4, [1,3], [3.,4.])\n",
    "\n",
    "w = np.array([0.4, 3.1, -1.4, -.5])\n",
    "print aDense.dot(w)\n",
    "print aSparse.dot(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(1.1c) Using sparse vectors to represent OHE features**\n",
    "Now let's see how we can represent the OHE features for points in our sample dataset.  Using the mapping defined by the OHE dictionary from Part (1a), manually define OHE features for the three sample data points using SparseVector format.  Any feature that occurs in a point should have the value 1.0.  For example, the `DenseVector` for a point with features 2 and 4 would be `[0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Reminder of the sample features:\n",
    "+ **sampleOne = [(0, 'mouse'), (1, 'black')]**\n",
    "+ **sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]**\n",
    "+ **sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]**\n",
    "\n",
    "and we have a dictionary **sampleOHEDictManual = {(0, 'bear'):0, (0, 'cat'):1, (0, 'mouse'):2, (1, 'black'):3, (1, 'tabby'):4, (2, 'mouse'):5, (2, 'salmon'):6}** to label the OHE feature. In the **Sparse vector** rep, they can be writtne as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleOneOHEFeatManual = SparseVector(7,[2,3],[1.,1.])\n",
    "sampleTwoOHEFeatManual = SparseVector(7,[1,4,5],[1.,1.,1.])\n",
    "sampleThreeOHEFeatManual = SparseVector(7,[0,3,6],[1.,1.,1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 1.2: Define an OHE function **\n",
    "Next we will use the OHE dictionary from (1.1a) to programatically generate OHE features from the original categorical data.  First write a function called `oneHotEncoding` that creates OHE feature vectors in `SparseVector` format.  Then use this function to create OHE features for the first sample data point and verify that the result matches the result from (1.1c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def oneHotEncoding(rawFeats, OHEDict, numOHEFeats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "    Note:\n",
    "        You should ensure that the indices used to create a SparseVector are sorted.\n",
    "    Args:\n",
    "        rawFeats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sampleOne)\n",
    "        OHEDict (dict): A mapping of (featureID, value) to unique integer.\n",
    "        numOHEFeats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length numOHEFeats with indicies equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    positionIndex = []\n",
    "    for features in rawFeats:\n",
    "        positionIndex.append(OHEDict[features])\n",
    "    value = [1.0]*len(positionIndex)\n",
    "    return SparseVector(numOHEFeats, sorted(positionIndex), value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `oneHotEncoding` function to create OHE features for all 3 data points in the toy sample dataset RDD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseVector(7, {2: 1.0, 3: 1.0}), SparseVector(7, {1: 1.0, 4: 1.0, 5: 1.0}), SparseVector(7, {0: 1.0, 3: 1.0, 6: 1.0})]\n"
     ]
    }
   ],
   "source": [
    "sampleOHEData = sampleDataRDD.map(lambda x: oneHotEncoding(x, sampleOHEDictManual, len(sampleOHEDictManual)))\n",
    "print sampleOHEData.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Part 2: Construct an OHE dictionary **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 2.1: Pair RDD of `(featureID, category)` in the toy example**\n",
    "Here, we will mention how to preare the OHE dictionary. To start, create an RDD of distinct `(featureID, category)` tuples. In our sample dataset, the 7 items in the resulting RDD are `(0, 'bear')`, `(0, 'cat')`, `(0, 'mouse')`, `(1, 'black')`, `(1, 'tabby')`, `(2, 'mouse')`, `(2, 'salmon')`. Notably `'black'` appears twice in the dataset but only contributes one item to the RDD: `(1, 'black')`, while `'mouse'` also appears twice and contributes two items: `(0, 'mouse')` and `(2, 'mouse')`.  Use [flatMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.flatMap) and [distinct](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.distinct)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that after reading data from text file, the toy sample RDD shows as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 'mouse'), (1, 'black')], [(0, 'cat'), (1, 'tabby'), (2, 'mouse')], [(0, 'bear'), (1, 'black'), (2, 'salmon')]]\n"
     ]
    }
   ],
   "source": [
    "print sampleDataRDD.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to use `flatMap` to smear the \"barrier\" between the samples and `distinct()` to make the elements in the list unique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleDistinctFeats = sampleDataRDD.flatMap(lambda x: x).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 'mouse'), (0, 'cat'), (0, 'bear'), (2, 'salmon'), (1, 'tabby'), (1, 'black'), (0, 'mouse')]\n"
     ]
    }
   ],
   "source": [
    "print sampleDistinctFeats.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see all OHE features are in a list. This can help us to construct the OHE feature dictionary in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 2.2: OHE Dictionary from distinct features **\n",
    "\n",
    "The above shows using `flatMap` to generate the OHE feature dictionary. But we need a more systematic way to generate the OHE feature dictionary.\n",
    "\n",
    "Here are procedures. First create an `RDD` of key-value tuples, where each `(featureID, category)` tuple in `sampleDistinctFeats` is a key and the values are distinct integers ranging from 0 to (number of keys - 1).  Then convert this `RDD` into a dictionary, which can be done using the `collectAsMap` action.  Note that there is no unique mapping from keys to values, as all we require is that each `(featureID, category)` key be mapped to a unique integer between 0 and the number of keys.  In this exercise, any valid mapping is acceptable.  Use [zipWithIndex](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.zipWithIndex) followed by [collectAsMap](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.collectAsMap).\n",
    "\n",
    "In our sample dataset, one valid list of key-value tuples is: `[((0, 'bear'), 0), ((2, 'salmon'), 1), ((1, 'tabby'), 2), ((2, 'mouse'), 3), ((0, 'mouse'), 4), ((0, 'cat'), 5), ((1, 'black'), 6)]`. The dictionary **sampleOHEDictManual** defined in Sec.(1.1a) illustrates another valid mapping between keys and integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use `zipWithIndex()` to designate the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((2, 'mouse'), 0), ((0, 'cat'), 1), ((0, 'bear'), 2), ((2, 'salmon'), 3), ((1, 'tabby'), 4), ((1, 'black'), 5), ((0, 'mouse'), 6)]\n"
     ]
    }
   ],
   "source": [
    "sampleOHEDict = (sampleDistinctFeats.zipWithIndex())\n",
    "print sampleOHEDict.take(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use `collectAsMap()` to collect and also convert to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'> {(2, 'mouse'): 0, (0, 'cat'): 1, (0, 'bear'): 2, (2, 'salmon'): 3, (1, 'tabby'): 4, (1, 'black'): 5, (0, 'mouse'): 6}\n"
     ]
    }
   ],
   "source": [
    "sampleOHEDict = (sampleDistinctFeats.zipWithIndex().collectAsMap())\n",
    "print type(sampleOHEDict), sampleOHEDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the keys are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'> [(2, 'mouse'), (0, 'cat'), (0, 'bear'), (2, 'salmon'), (1, 'tabby'), (1, 'black'), (0, 'mouse')]\n"
     ]
    }
   ],
   "source": [
    " print type(sampleOHEDict.keys()), sampleOHEDict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sec. 2.3: Automated creation of an OHE dictionary **\n",
    "Now we can combine the procedures from Sec. 2.1 and 2.2 to write a systematic function that takes an input dataset and outputs an OHE dictionary. Usually the amount of data is intractable. Then use this function to create an OHE dictionary for the sample dataset, and verify that it matches the dictionary from Sec. 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createOneHotDict(inputData):\n",
    "    \"\"\"Creates a one-hot-encoder dictionary based on the input data.\n",
    "    Args:\n",
    "        inputData (RDD of lists of (int, str)): An RDD of observations where each observation is\n",
    "            made up of a list of (featureID, value) tuples.\n",
    "    Returns:\n",
    "        dict: A dictionary where the keys are (featureID, value) tuples and map to values that are\n",
    "            unique integers.\n",
    "    \"\"\"\n",
    "    return inputData.flatMap(lambda x: x).distinct().zipWithIndex().collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use the `createOneHotDict` function to test our toy example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(2, 'mouse'): 0, (0, 'cat'): 1, (0, 'bear'): 2, (2, 'salmon'): 3, (1, 'tabby'): 4, (1, 'black'): 5, (0, 'mouse'): 6}\n"
     ]
    }
   ],
   "source": [
    "sampleOHEDictAuto = createOneHotDict(sampleDataRDD)\n",
    "print sampleOHEDictAuto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sec. 3: Parse CTR data and generate OHE features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can proceed, you'll first need to obtain the data from Criteo.  If you have already completed this step in the setup lab, just run the cells below and the data will be loaded into the `rawData` RDD variable.\n",
    "\n",
    "Below is Criteo's data sharing agreement.  After you accept the agreement, you can obtain the download URL by right-clicking on the \"Download Sample\" button and clicking \"Copy link address\" or \"Copy Link Location\", depending on your browser.  Paste the URL into the `# TODO` cell below.  The file is 8.4 MB compressed.  The script below will download the file to the virtual machine (VM) and then extract the data. Open the [Criteo agreement](http://labs.criteo.com/downloads/2014-kaggle-display-advertising-challenge-dataset/) in a separate browser tab.  After you accept the agreement, you can obtain the download URL by right-clicking on the \"Download Sample\" button and clicking \"Copy link address\" or \"Copy Link Location\", depending on your browser.\n",
    "\n",
    "Note that the download could take a few minutes, depending upon your connection speed. The following is that I assume we have downloaded the data and store in the folder. There are 100000 observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'0,1,1,5,0,1382,4,15,2,181,1,2,,2,68fd1e64,80e26c9b,fb936136,7b4723c4,25c83c98,7e0ccccf,de7995b8,1f89b562,a73ee510,a8cd5504,b2cb9c98,37c9c164,2824a5f6,1adce6ef,8ba8b39a,891b62e7,e5ba7672,f54016b9,21ddcdc9,b1252a9d,07b5194c,,3a171ecb,c5c50484,e8b83407,9727dd16', u'0,2,0,44,1,102,8,2,2,4,1,1,,4,68fd1e64,f0cf0024,6f67f7e5,41274cd7,25c83c98,fe6b92e5,922afcc0,0b153874,a73ee510,2b53e5fb,4f1b46f3,623049e6,d7020589,b28479f6,e6c5b5cd,c92f3b61,07c540c4,b04e4670,21ddcdc9,5840adea,60f6221e,,3a171ecb,43f13e8b,e8b83407,731c3655']\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "rawData = (sc.textFile('data/cs190/dac_sample.txt', 2)\n",
    "               .map(lambda x: x.replace('\\t', ',')))  # work with either ',' or '\\t' separated data\n",
    "print rawData.take(2)\n",
    "print rawData.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 3.1: Parse data and splitting into training, validation and test sets **\n",
    "We are now ready to start working with the actual CTR data, and our first task involves splitting it into training, validation, and test sets.  Use the [randomSplit method](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.randomSplit) with the specified weights and seed to create RDDs storing each of these datasets, and then [cache](https://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.cache) each of these RDDs, as we will be accessing them multiple times in the remainder of this lab. Finally, compute the size of each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79911 10075 10014 100000\n"
     ]
    }
   ],
   "source": [
    "weights = [.8, .1, .1]\n",
    "seed = 42\n",
    "# Use randomSplit with weights and seed\n",
    "rawTrainData, rawValidationData, rawTestData = rawData.randomSplit(weights, seed)\n",
    "# Cache the data\n",
    "rawTrainData.cache()\n",
    "rawValidationData.cache()\n",
    "rawTestData.cache()\n",
    "\n",
    "nTrain = rawTrainData.count()\n",
    "nVal = rawValidationData.count()\n",
    "nTest = rawTestData.count()\n",
    "print nTrain, nVal, nTest, nTrain + nVal + nTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 3.2: Determine the number of OHE features**\n",
    "We will now parse the raw training data to create an RDD that we can subsequently use to create an OHE dictionary. Note from the `rawData.take()` command shows that each raw data point is a string containing several fields separated by some delimiter.  For now, we will ignore the first field (which is the 0/1 label), and parse the remaining fields (or raw features).  To do this, complete the implemention of the `parsePoint` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parsePoint(point):\n",
    "    \"\"\"Converts a comma separated string into a list of (featureID, value) tuples.\n",
    "    Note:\n",
    "        featureIDs should start at 0 and increase to the number of features - 1.\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "    Returns:\n",
    "        list: A list of (featureID, value) tuples.\n",
    "    \"\"\"\n",
    "    point = point.split(',')\n",
    "    return [(i, point) for i, point in enumerate(point[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'0,1,1,5,0,1382,4,15,2,181,1,2,,2,68fd1e64,80e26c9b,fb936136,7b4723c4,25c83c98,7e0ccccf,de7995b8,1f89b562,a73ee510,a8cd5504,b2cb9c98,37c9c164,2824a5f6,1adce6ef,8ba8b39a,891b62e7,e5ba7672,f54016b9,21ddcdc9,b1252a9d,07b5194c,,3a171ecb,c5c50484,e8b83407,9727dd16', u'0,2,0,44,1,102,8,2,2,4,1,1,,4,68fd1e64,f0cf0024,6f67f7e5,41274cd7,25c83c98,fe6b92e5,922afcc0,0b153874,a73ee510,2b53e5fb,4f1b46f3,623049e6,d7020589,b28479f6,e6c5b5cd,c92f3b61,07c540c4,b04e4670,21ddcdc9,5840adea,60f6221e,,3a171ecb,43f13e8b,e8b83407,731c3655']\n"
     ]
    }
   ],
   "source": [
    "print rawTrainData.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using  `parsePoint` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, u'1'), (1, u'1'), (2, u'5'), (3, u'0'), (4, u'1382'), (5, u'4'), (6, u'15'), (7, u'2'), (8, u'181'), (9, u'1'), (10, u'2'), (11, u''), (12, u'2'), (13, u'68fd1e64'), (14, u'80e26c9b'), (15, u'fb936136'), (16, u'7b4723c4'), (17, u'25c83c98'), (18, u'7e0ccccf'), (19, u'de7995b8'), (20, u'1f89b562'), (21, u'a73ee510'), (22, u'a8cd5504'), (23, u'b2cb9c98'), (24, u'37c9c164'), (25, u'2824a5f6'), (26, u'1adce6ef'), (27, u'8ba8b39a'), (28, u'891b62e7'), (29, u'e5ba7672'), (30, u'f54016b9'), (31, u'21ddcdc9'), (32, u'b1252a9d'), (33, u'07b5194c'), (34, u''), (35, u'3a171ecb'), (36, u'c5c50484'), (37, u'e8b83407'), (38, u'9727dd16')], [(0, u'2'), (1, u'0'), (2, u'44'), (3, u'1'), (4, u'102'), (5, u'8'), (6, u'2'), (7, u'2'), (8, u'4'), (9, u'1'), (10, u'1'), (11, u''), (12, u'4'), (13, u'68fd1e64'), (14, u'f0cf0024'), (15, u'6f67f7e5'), (16, u'41274cd7'), (17, u'25c83c98'), (18, u'fe6b92e5'), (19, u'922afcc0'), (20, u'0b153874'), (21, u'a73ee510'), (22, u'2b53e5fb'), (23, u'4f1b46f3'), (24, u'623049e6'), (25, u'd7020589'), (26, u'b28479f6'), (27, u'e6c5b5cd'), (28, u'c92f3b61'), (29, u'07c540c4'), (30, u'b04e4670'), (31, u'21ddcdc9'), (32, u'5840adea'), (33, u'60f6221e'), (34, u''), (35, u'3a171ecb'), (36, u'43f13e8b'), (37, u'e8b83407'), (38, u'731c3655')]]\n"
     ]
    }
   ],
   "source": [
    "parsedTrainFeat = rawTrainData.map(lambda x: parsePoint(x))\n",
    "print parsedTrainFeat.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element is parsed as (featureID, categories). The featureID = 0,1,..38, and different featureID can have different categories. To count the number of OHE fetures, we should identify how many unique characters in each features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numCategories = parsedTrainFeat.flatMap(lambda x: x).distinct() \\\n",
    "                 .map(lambda x: (x[0], 1)).reduceByKey(lambda x, y: x + y).sortByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 144), (1, 2467), (2, 855), (3, 129), (4, 20311), (5, 1890), (6, 567), (7, 142), (8, 1796), (9, 8), (10, 81), (11, 62), (12, 252), (13, 471), (14, 492), (15, 36044), (16, 21331), (17, 131), (18, 12), (19, 7221), (20, 233), (21, 3), (22, 9905), (23, 3678), (24, 33988), (25, 2741), (26, 25), (27, 4844), (28, 28762), (29, 10), (30, 2379), (31, 1223), (32, 4), (33, 31887), (34, 11), (35, 14), (36, 10799), (37, 49), (38, 8325)]\n"
     ]
    }
   ],
   "source": [
    "print numCategories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows featureID =0, there are 144 distinct categories, featureID=1, there are 2467.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 2467 855\n"
     ]
    }
   ],
   "source": [
    "print numCategories[0][1], numCategories[1][1], numCategories[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 38 features for each observaiton. Like the sample example, the featureID = 0, labeling 'anamial', there are 3 different descriptions: 'mouse', 'cat', and 'bear'; for featureID=1, labeling 'color', two: 'black' and 'tabby'; for eatureID = 2, labeling 'food', two: 'mouse' and 'salmon'. Then we will know the total size of sparse vector to generate should be 3+2+2=7. In our dataset, we should have 144+2467+...+8325 =233286, which gives the number of OHE features and determine the size of the sparse vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233286\n"
     ]
    }
   ],
   "source": [
    "totalSize =0\n",
    "for i in range(len(numCategories)):\n",
    "    totalSize += numCategories[i][1]\n",
    "print totalSize    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sec. 3.3: Create an OHE dictionary from the dataset **\n",
    "Note that parsePoint returns a data point as a list of `(featureID, category)` tuples, which is the same format as the sample dataset studied in Sec. 1 and 2 of this lab.  Using this observation, create an OHE dictionary using the function implemented in Sec. 2.3. Note that we will assume for simplicity that all features in our CTR dataset are categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233286\n"
     ]
    }
   ],
   "source": [
    "ctrOHEDict = createOneHotDict(parsedTrainFeat)\n",
    "numCtrOHEFeats = len(ctrOHEDict.keys())\n",
    "'''ctrOHEDict is the size of indices in the sparse Vector, i.e. there will be 233286 distinct OHE features.\n",
    "   In other words, in the DenseVector rep, it will be [0,0,1,0,0,...1,0....1]; each vector has 233286 components'''\n",
    "print numCtrOHEFeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the sparse vector to denote our OEH features is 233286. \n",
    "\n",
    "ctrOHEDict[(1,'a')] is the position index of the key=(1,'a') at featureID=1, and 'a' category.\n",
    "e.g. the key (28, u'afc930ae') is at 0-th spot, i.e. in the DenseVector rep it is [1,0,0...];\n",
    "the key (16, u'0e4666ea') is at 116918-th spot; it is [0,0...,0,1,0,0...0], where 1 is at 116918-th spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (16, u'0e4666ea') 116918\n",
      "2 (28, u'afc930ae') 0\n",
      "3 (24, u'5af66cdb') 116921\n",
      "4 (5, u'1454') 116940\n",
      "5 (2, u'105') 116924\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for ch in ctrOHEDict:\n",
    "    i += 1\n",
    "    if i <=5: print i, ch, ctrOHEDict[ch]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 3.4: Using LabeledPoint to store label and OHE features **\n",
    "Now let's use this OHE dictionary by starting with the raw training data and creating an RDD of [LabeledPoint](http://spark.apache.org/docs/1.3.1/api/python/pyspark.mllib.html#pyspark.mllib.regression.LabeledPoint) objects using OHE features.  To do this, complete the implementation of the `parseOHEPoint` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the raw data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'0,1,1,5,0,1382,4,15,2,181,1,2,,2,68fd1e64,80e26c9b,fb936136,7b4723c4,25c83c98,7e0ccccf,de7995b8,1f89b562,a73ee510,a8cd5504,b2cb9c98,37c9c164,2824a5f6,1adce6ef,8ba8b39a,891b62e7,e5ba7672,f54016b9,21ddcdc9,b1252a9d,07b5194c,,3a171ecb,c5c50484,e8b83407,9727dd16']\n"
     ]
    }
   ],
   "source": [
    "print rawTrainData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseOHEPoint(point, OHEDict, numOHEFeats):\n",
    "    \"\"\"Obtain the label and feature vector for this raw observation.\n",
    "    Note:\n",
    "        You must use the function `oneHotEncoding` in this implementation or later portions\n",
    "        of this lab may not function as expected.\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest\n",
    "            are features.\n",
    "        OHEDict (dict of (int, str) to int): Mapping of (featureID, value) to unique integer.\n",
    "        numOHEFeats (int): The number of unique features in the training dataset.\n",
    "    Returns:\n",
    "        LabeledPoint: Contains the label for the observation and the one-hot-encoding of the\n",
    "            raw features based on the provided OHE dictionary.\n",
    "    \"\"\"\n",
    "    point = point.split(',')\n",
    "    label = point[0]\n",
    "    features = [(i, point) for i, point in enumerate(point[1:])]\n",
    "    return LabeledPoint(label, oneHotEncoding(features, OHEDict, numOHEFeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[81] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHETrainData = rawTrainData.map(lambda point: parseOHEPoint(point, ctrOHEDict, numCtrOHEFeats))\n",
    "OHETrainData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, (233286,[382,3101,6842,8311,8911,11887,12893,16211,17631,18646,23513,29366,33157,39536,55820,61797,81485,82753,93671,96986,109720,110662,112139,120263,128571,132400,132805,140595,160666,185457,190322,191105,195902,202638,204242,206037,222753,225966,229941],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))]\n"
     ]
    }
   ],
   "source": [
    "print OHETrainData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first item is the lable = y. And the second item is a Sparse vector rep, which has three parts: size, index list and the value list. In the following we can see the classes of these three parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.mllib.regression.LabeledPoint'>\n"
     ]
    }
   ],
   "source": [
    "print type(OHETrainData.take(1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.mllib.linalg.SparseVector'>\n"
     ]
    }
   ],
   "source": [
    "print type(OHETrainData.take(1)[0].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'float'>\n"
     ]
    }
   ],
   "source": [
    "print type(OHETrainData.take(1)[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check that oneHotEncoding function was used in parseOHEPoint\n",
    "backupOneHot = oneHotEncoding\n",
    "oneHotEncoding = None\n",
    "withOneHot = False\n",
    "try: parseOHEPoint(rawTrainData.take(1)[0], ctrOHEDict, numCtrOHEFeats)\n",
    "except TypeError: withOneHot = True\n",
    "oneHotEncoding = backupOneHot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 3.5: Handling unseen features **\n",
    "We naturally would like to repeat the process from Sec. 3.4, e.g., to compute OHE features for the validation and test datasets.  However, we must be careful, as some categorical values will likely appear in new data that did not exist in the training data. To deal with this situation, update the `oneHotEncoding()` function from Sec. 1.2 to ignore previously unseen categories, and then compute OHE features for the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def oneHotEncoding(rawFeats, OHEDict, numOHEFeats):\n",
    "    \"\"\"Produce a one-hot-encoding from a list of features and an OHE dictionary.\n",
    "    Note:\n",
    "        If a (featureID, value) tuple doesn't have a corresponding key in OHEDict it should be\n",
    "        ignored.\n",
    "    Args:\n",
    "        rawFeats (list of (int, str)): The features corresponding to a single observation.  Each\n",
    "            feature consists of a tuple of featureID and the feature's value. (e.g. sampleOne)\n",
    "        OHEDict (dict): A mapping of (featureID, value) to unique integer.\n",
    "        numOHEFeats (int): The total number of unique OHE features (combinations of featureID and\n",
    "            value).\n",
    "    Returns:\n",
    "        SparseVector: A SparseVector of length numOHEFeats with indicies equal to the unique\n",
    "            identifiers for the (featureID, value) combinations that occur in the observation and\n",
    "            with values equal to 1.0.\n",
    "    \"\"\"\n",
    "    ## ignore construction OHE if features shown in the validation set are not in the OHEDict (from training set).\n",
    "    ## therefore the sparse vector size is still 233286.\n",
    "    positionIndex = []\n",
    "    for features in rawFeats:\n",
    "        if features in OHEDict: positionIndex.append(OHEDict[features])\n",
    "    value = [1.0]*len(positionIndex)\n",
    "    return SparseVector(numOHEFeats, sorted(positionIndex), value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After updating the `oneHotEncoding()` function function, we can prepare validation and test datasets in terms of OHE features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[102] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OHEValidationData = rawValidationData.map(lambda point: parseOHEPoint(point, ctrOHEDict, numCtrOHEFeats))\n",
    "OHETestData = rawTestData.map(lambda point: parseOHEPoint(point, ctrOHEDict, numCtrOHEFeats))\n",
    "OHEValidationData.cache()\n",
    "OHETestData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, (233286,[7623,9238,15597,21650,31238,36177,36577,39536,49203,61797,66635,67253,68245,68344,73075,76724,81421,81485,92068,96986,98511,109720,117014,121550,141683,146472,147618,171119,184096,184644,185457,185819,194734,198514,201019,210722,213593,222178,227716],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))]\n"
     ]
    }
   ],
   "source": [
    "print OHEValidationData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print [OHEValidationData.take(10)[i].label for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Sec. 4: CTR prediction and logloss evaluation **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 4.1: Logistic regression**\n",
    "We are now ready to train our first CTR classifier.  A natural classifier to use in this setting is logistic regression, since it models the probability of a click-through event rather than returning a binary response, and when working with rare events, probabilistic predictions are useful.  First use [LogisticRegressionWithSGD](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithSGD) to train a model using `OHETrainData` with the given hyperparameter configuration.  `LogisticRegressionWithSGD` returns a [LogisticRegressionModel](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.regression.LogisticRegressionModel).  Next, use the `LogisticRegressionModel.weights` and `LogisticRegressionModel.intercept` attributes to print out the model's parameters.  Note that these are the names of the object's attributes and should be called using a syntax like `model.weights` for a given `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import LogisticRegressionWithSGD\n",
    "\n",
    "# fixed hyperparameters\n",
    "numIters = 50\n",
    "stepSize = 10.\n",
    "regParam = 1e-6\n",
    "regType = 'l2'\n",
    "includeIntercept = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4589923685357562, -0.37973707648623972, -0.3699655826675331, -0.36934962879928285, -0.32697945415010637] 0.56455084025\n"
     ]
    }
   ],
   "source": [
    "model0 = LogisticRegressionWithSGD.train(OHETrainData, iterations=numIters, step=stepSize,  \\\n",
    "                                         initialWeights=None, regParam=regParam, regType=regType, \\\n",
    "                                         intercept=includeIntercept)\n",
    "sortedWeights = sorted(model0.weights)\n",
    "print sortedWeights[:5], model0.intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the weights is a 233286-dimensional vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233286\n"
     ]
    }
   ],
   "source": [
    "print len(sortedWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 4.2: Define Log loss **\n",
    "Throughout this lab, we will use log loss to evaluate the quality of models.  Log loss is defined as: \n",
    "####$$  \\begin{align} \\scriptsize \\ell_{log}(p, y) = \\begin{cases} -\\log (p) & \\text{if } y = 1 \\\\\\ -\\log(1-p) & \\text{if } y = 0 \\end{cases} \\end{align} $$ \n",
    "where $ \\scriptsize p$ is a probability between 0 and 1 and $ \\scriptsize y$ is a label of either 0 or 1. Log loss is a standard evaluation criterion when predicting rare-events such as click-through rate prediction (it is also the criterion used in the [Criteo Kaggle competition](https://www.kaggle.com/c/criteo-display-ad-challenge)).  Write a function to compute log loss, and evaluate it on some sample inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "def computeLogLoss(p, y):\n",
    "    \"\"\"Calculates the value of log loss for a given probabilty and label.\n",
    "    Note:\n",
    "        log(0) is undefined, so when p is 0 we need to add a small value (epsilon) to it\n",
    "        and when p is 1 we need to subtract a small value (epsilon) from it.\n",
    "    Args:\n",
    "        p (float): A probabilty between 0 and 1.\n",
    "        y (int): A label.  Takes on the values 0 and 1.\n",
    "    Returns:\n",
    "        float: The log loss value.\n",
    "    \"\"\"\n",
    "    epsilon = 10e-12\n",
    "    if y == 0:\n",
    "        return -log(abs(1.0-(p+epsilon)))\n",
    "    elif y == 1:\n",
    "        return -log(abs(p+epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69314718054\n",
      "0.69314718058\n",
      "0.0100503358434\n",
      "4.60517018699\n",
      "4.60517018499\n",
      "0.0100503358636\n",
      "25.3284360229\n",
      "-1.00000008274e-11\n",
      "25.3284359402\n"
     ]
    }
   ],
   "source": [
    "print computeLogLoss(.5, 1)\n",
    "print computeLogLoss(.5, 0)\n",
    "print computeLogLoss(.99, 1)\n",
    "print computeLogLoss(.99, 0)\n",
    "print computeLogLoss(.01, 1)\n",
    "print computeLogLoss(.01, 0)\n",
    "print computeLogLoss(0, 1)\n",
    "print computeLogLoss(1, 1)\n",
    "print computeLogLoss(1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 4.3:  Log loss for the baseline model**\n",
    "Next we will use the function we wrote in Sec. 4.2 to compute the baseline log loss on the training data. A very **simple yet natural baseline model** is one where we always make the **same prediction independent of the given datapoint**, setting the predicted value equal to the fraction of training points that correspond to click-through events (i.e., where the label is one). Compute this value (which is simply the mean of the training labels), and then use it to compute the training log loss for the baseline model.  The log loss for multiple observations is the mean of the individual log loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22717773523\n",
      "Baseline Train Logloss = 0.536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note that our dataset has a very high click-through rate by design\n",
    "# In practice click-through rate can be one to two orders of magnitude lower\n",
    "classOneFracTrain = OHETrainData.filter(lambda x: x.label == 1).count()/float(OHETrainData.count())\n",
    "print classOneFracTrain\n",
    "logLossTrBase = OHETrainData.map(lambda x: computeLogLoss(classOneFracTrain, x.label)).sum()/float(OHETrainData.count())\n",
    "print 'Baseline Train Logloss = {0:.3f}\\n'.format(logLossTrBase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 4.4: Predicted probability **\n",
    "In order to compute the log loss for the model we trained in Sec. 4.1, we need to write code to generate predictions from this model. Write a function that computes the raw linear prediction from this logistic regression model and then passes it through a [sigmoid function](http://en.wikipedia.org/wiki/Sigmoid_function) $ \\scriptsize \\sigma(t) = (1+ e^{-t})^{-1} $ to return the model's probabilistic prediction. Then compute probabilistic predictions on the training data.\n",
    "\n",
    "Note that when incorporating an intercept into our predictions, we simply add the intercept to the value of the prediction obtained from the weights and features.  Alternatively, if the intercept was included as the first weight, we would need to add a corresponding feature to our data where the feature has the value one.  This is not the case here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import exp #  exp(-t) = e^-t\n",
    "def getP(x, w, intercept):\n",
    "    \"\"\"Calculate the probability for an observation given a set of weights and intercept.\n",
    "    Note:\n",
    "        We'll bound our raw prediction between 20 and -20 for numerical purposes.\n",
    "    Args:\n",
    "        x (SparseVector): A vector with values of 1.0 for features that exist in this\n",
    "            observation and 0.0 otherwise.\n",
    "        w (DenseVector): A vector of weights (betas) for the model.\n",
    "        intercept (float): The model's intercept.\n",
    "    Returns:\n",
    "        float: A probability between 0 and 1.\n",
    "    \"\"\"\n",
    "    rawPrediction = x.dot(w)+intercept\n",
    "    # Bound the raw prediction value\n",
    "    '''the raw prediction means t=x*w not 1/(1+e(-t))'''\n",
    "    rawPrediction = min(rawPrediction, 20)\n",
    "    rawPrediction = max(rawPrediction, -20)\n",
    "    return 1.0/(1.0+exp(-rawPrediction)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30262882023911125, 0.10362661997434075, 0.283634247838756, 0.17846102057880114, 0.5389775379218853]\n"
     ]
    }
   ],
   "source": [
    "trainingPredictions = OHETrainData.map(lambda x: getP(x.features, model0.weights, model0.intercept))\n",
    "print trainingPredictions.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 4.5: Evaluate the model **\n",
    "We are now ready to evaluate the quality of the model we trained in Sec. 4.1. To do this, first write a general function that takes as input a model and data, and outputs the log loss.  Then run this function on the OHE training data, and compare the result with the baseline log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluateResults(model, data):\n",
    "    \"\"\"Calculates the log loss for the data given the model.\n",
    "    Args:\n",
    "        model (LogisticRegressionModel): A trained logistic regression model.\n",
    "        data (RDD of LabeledPoint): Labels and features for each observation.\n",
    "    Returns:\n",
    "        float: Log loss for the data.\n",
    "    \"\"\"\n",
    "    w = model.weights\n",
    "    intercept = model.intercept\n",
    "    return data.map(lambda x: computeLogLoss(getP(x.features, w, intercept), x.label) ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logloss of the baseline and logistic regression models are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE Features Train Logloss:\n",
      "\tBaseline = 0.536\n",
      "\tLogReg = 0.457\n"
     ]
    }
   ],
   "source": [
    "logLossTrLR0 = evaluateResults(model0, OHETrainData)\n",
    "print ('OHE Features Train Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(logLossTrBase, logLossTrLR0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 4.6: Validation log loss **\n",
    "Next, following the same logic as in Sec. 4.3 and 4.5, compute the **validation log loss** for both the baseline and logistic regression models. Notably, the baseline model for the **validation data** should still be based on the label fraction from the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4.6a) Baseline model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classOneFracVal = OHEValidationData.filter(lambda x: x.label==1).count()/float(OHEValidationData.count())\n",
    "logLossValBase = OHEValidationData.map(lambda x: computeLogLoss(classOneFracVal, x.label)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4.6b) Logistic regression model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHE Features Validation Logloss:\n",
      "\tBaseline = 0.527\n",
      "\tLogReg = 0.457\n"
     ]
    }
   ],
   "source": [
    "logLossValLR0 = evaluateResults(model0, OHEValidationData)\n",
    "print ('OHE Features Validation Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(logLossValBase, logLossValLR0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(4.6c) Logistic regression model for test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.464431773688\n"
     ]
    }
   ],
   "source": [
    "logLossTestLR0 = evaluateResults(model0, OHETestData)\n",
    "print logLossTestLR0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sec. 4.7: Grid Search**\n",
    "\n",
    "Now we try to tune distinict regularization parameters, and search for optimal reg parameter to minimize the logloss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.456943802647\n",
      "1e-06 0.456956712744\n",
      "0.001 0.457610849021\n",
      "0.1 0.531126125929\n",
      "1.0 15.5948582979\n"
     ]
    }
   ],
   "source": [
    "for regParam in [0, 1e-6, 1e-3, 0.1, 1.0]:\n",
    "    LRmodels = LogisticRegressionWithSGD.train(OHETrainData, iterations=numIters, step=stepSize,  \\\n",
    "                                         initialWeights=None, regParam=regParam, regType=regType, \\\n",
    "                                         intercept=includeIntercept)\n",
    "    logLossValLR0 = evaluateResults(LRmodels, OHEValidationData)\n",
    "    print regParam, logLossValLR0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see the previous setup on regParam = 1e-6 has giveb us a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sec. 4.8: ROC curve **\n",
    "We will now visualize how well the model predicts our target.  To do this we generate a plot of the ROC curve.  The ROC curve shows us the trade-off between the false positive rate and true positive rate, as we liberalize the threshold required to predict a positive outcome.  A random model is represented by the dashed line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3EAAAIdCAYAAACTNfTZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb00c5bcc>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labelsAndScores = OHEValidationData.map(lambda lp:\n",
    "                                            (lp.label, getP(lp.features, model0.weights, model0.intercept)))\n",
    "labelsAndWeights = labelsAndScores.collect()\n",
    "labelsAndWeights.sort(key=lambda (k, v): v, reverse=True)\n",
    "labelsByWeight = np.array([k for (k, v) in labelsAndWeights])\n",
    "\n",
    "length = labelsByWeight.size\n",
    "truePositives = labelsByWeight.cumsum()\n",
    "numPositive = truePositives[-1]\n",
    "falsePositives = np.arange(1.0, length + 1, 1.) - truePositives\n",
    "\n",
    "truePositiveRate = truePositives / numPositive\n",
    "falsePositiveRate = falsePositives / (length - numPositive)\n",
    "\n",
    "# Generate layout and plot data\n",
    "fig, ax = preparePlot(np.arange(0., 1.1, 0.1), np.arange(0., 1.1, 0.1))\n",
    "ax.set_xlim(-.05, 1.05), ax.set_ylim(-.05, 1.05)\n",
    "ax.set_ylabel('True Positive Rate (Sensitivity)')\n",
    "ax.set_xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.plot(falsePositiveRate, truePositiveRate, color='#8cbfd0', linestyle='-', linewidth=3.)\n",
    "plt.plot((0., 1.), (0., 1.), linestyle='--', color='#d6ebf2', linewidth=2.)  # Baseline model\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sec. 5: Reduce feature dimension via feature hashing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 5.1: Hash function **\n",
    "As we just saw, using a one-hot-encoding featurization can yield a model with good statistical accuracy.  However, the number of distinct categories across all features is quite large -- recall that we observed 233K categories in the training data in Sec. 3.3.  Moreover, the full Kaggle training dataset includes more than 33M distinct categories, and the Kaggle dataset itself is just a small subset of Criteo's labeled data.  Hence, featurizing via a one-hot-encoding representation would lead to a very large feature vector. To reduce the dimensionality of the feature space, we will use feature hashing.\n",
    "\n",
    "Below is the hash function that we will use for this part of the lab.  We will first use this hash function with the three sample data points from Sec. 1 to gain some intuition.  Specifically, run code to hash the three sample points using two different values for `numBuckets` and observe the resulting hashed feature dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "def hashFunction(numBuckets, rawFeats, printMapping=False):\n",
    "    \"\"\"Calculate a feature dictionary for an observation's features based on hashing.\n",
    "    Note:\n",
    "        Use printMapping=True for debug purposes and to better understand how the hashing works.\n",
    "    Args:\n",
    "        numBuckets (int): Number of buckets to use as features.\n",
    "        rawFeats (list of (int, str)): A list of features for an observation.  Represented as\n",
    "            (featureID, value) tuples.\n",
    "        printMapping (bool, optional): If true, the mappings of featureString to index will be\n",
    "            printed.\n",
    "    Returns:\n",
    "        dict of int to float:  The keys will be integers which represent the buckets that the\n",
    "            features have been hashed to.  The value for a given key will contain the count of the\n",
    "            (featureID, value) tuples that have hashed to that key.\n",
    "    \"\"\"\n",
    "    mapping = {}\n",
    "    for ind, category in rawFeats:\n",
    "        featureString = category + str(ind)\n",
    "        mapping[featureString] = int(int(hashlib.md5(featureString).hexdigest(), 16) % numBuckets)\n",
    "    if(printMapping): print mapping\n",
    "    sparseFeatures = defaultdict(float)\n",
    "    for bucket in mapping.values():\n",
    "        sparseFeatures[bucket] += 1.0\n",
    "    return dict(sparseFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(5.1a) Hash feature for the toy example**\n",
    "Reminder of the sample values:\n",
    "+ sampleOne = [(0, 'mouse'), (1, 'black')]\n",
    "+ sampleTwo = [(0, 'cat'), (1, 'tabby'), (2, 'mouse')]\n",
    "+ sampleThree =  [(0, 'bear'), (1, 'black'), (2, 'salmon')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we have the OHE feature dictionary as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(2, 'mouse'): 5, (0, 'cat'): 1, (0, 'bear'): 0, (2, 'salmon'): 6, (1, 'tabby'): 4, (1, 'black'): 3, (0, 'mouse'): 2}\n"
     ]
    }
   ],
   "source": [
    "print sampleOHEDictManual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the hash function to construct the feature, we will have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'black1': 2, 'mouse0': 3}\n",
      "{'cat0': 0, 'tabby1': 0, 'mouse2': 2}\n",
      "{'bear0': 0, 'black1': 2, 'salmon2': 1}\n",
      "\n",
      "{'black1': 14, 'mouse0': 31}\n",
      "{'cat0': 40, 'tabby1': 16, 'mouse2': 62}\n",
      "{'bear0': 72, 'black1': 14, 'salmon2': 5}\n",
      "\n",
      "\t\t 4 Buckets \t\t\t 100 Buckets\n",
      "SampleOne:\t {2: 1.0, 3: 1.0}\t\t {14: 1.0, 31: 1.0}\n",
      "SampleTwo:\t {0: 2.0, 2: 1.0}\t\t {40: 1.0, 16: 1.0, 62: 1.0}\n",
      "SampleThree:\t {0: 1.0, 1: 1.0, 2: 1.0}\t {72: 1.0, 5: 1.0, 14: 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Use four buckets\n",
    "sampOneFourBuckets = hashFunction(4, sampleOne, True)\n",
    "sampTwoFourBuckets = hashFunction(4, sampleTwo, True)\n",
    "sampThreeFourBuckets = hashFunction(4, sampleThree, True)\n",
    "print \n",
    "# Use one hundred buckets\n",
    "sampOneHundredBuckets = hashFunction(100, sampleOne, True)\n",
    "sampTwoHundredBuckets = hashFunction(100, sampleTwo, True)\n",
    "sampThreeHundredBuckets = hashFunction(100, sampleThree, True)\n",
    "print\n",
    "print '\\t\\t 4 Buckets \\t\\t\\t 100 Buckets'\n",
    "print 'SampleOne:\\t {0}\\t\\t {1}'.format(sampOneFourBuckets, sampOneHundredBuckets)\n",
    "print 'SampleTwo:\\t {0}\\t\\t {1}'.format(sampTwoFourBuckets, sampTwoHundredBuckets)\n",
    "print 'SampleThree:\\t {0}\\t {1}'.format(sampThreeFourBuckets, sampThreeHundredBuckets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ** (5.1b) Creating hashed features **\n",
    "Next we will use this hash function to create hashed features for our CTR datasets. First write a function that uses the hash function from Sec. 5.1 with numBuckets = $ \\scriptsize 2^{15} \\approx 33K $ to create a `LabeledPoint` with hashed features stored as a `SparseVector`.  Then use this function to create new training, validation and test datasets with hashed features. The `parsedHashPoint` function is similar to `parseOHEPoint` from Sec. 3.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseHashPoint(point, numBuckets):\n",
    "    \"\"\"Create a LabeledPoint for this observation using hashing.\n",
    "    Args:\n",
    "        point (str): A comma separated string where the first value is the label and the rest are\n",
    "            features.\n",
    "        numBuckets: The number of buckets to hash to.\n",
    "    Returns:\n",
    "        LabeledPoint: A LabeledPoint with a label (0.0 or 1.0) and a SparseVector of hashed\n",
    "            features.\n",
    "    \"\"\"\n",
    "    point = point.split(',')\n",
    "    label = point[0]\n",
    "    features = [(i, point) for i, point in enumerate(point[1:])]\n",
    "    hashTable = hashFunction(numBuckets, features, True)\n",
    "    positionIndex = []\n",
    "    value = []      ## note now value is no longer just [1,1,1..] since in the hash table\n",
    "                    ## there will be some conflcut, so sometimes it is 2,3.. i.e. [1,1,2,1,3,..]\n",
    "    for ch in hashTable:\n",
    "        positionIndex.append(ch)\n",
    "        value.append(hashTable[ch])\n",
    "    v = sorted(range(len(positionIndex)), key=lambda k: positionIndex[k])\n",
    "    sorted_value = [value[i] for i in v]\n",
    "    return LabeledPoint(label, SparseVector(numBuckets, sorted(positionIndex), sorted_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(0.0, (32768,[1305,2883,3807,4814,4866,4913,6952,7117,9985,10316,11512,11722,12365,13893,14735,15816,16198,17761,19274,21604,22256,22563,22785,24855,25202,25533,25721,26487,26656,27668,28211,29152,29402,29873,30039,31484,32493,32708],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]))]\n"
     ]
    }
   ],
   "source": [
    "numBucketsCTR = 2 ** 15\n",
    "hashTrainData = rawTrainData.map(lambda x: parseHashPoint(x, numBucketsCTR))\n",
    "hashTrainData.cache()\n",
    "hashValidationData = rawValidationData.map(lambda x: parseHashPoint(x, numBucketsCTR))\n",
    "hashValidationData.cache()\n",
    "hashTestData = rawTestData.map(lambda x: parseHashPoint(x, numBucketsCTR))\n",
    "hashTestData.cache()\n",
    "\n",
    "print hashTrainData.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 5.2: Sparsity **\n",
    "Since we have 33K hashed features versus 233K OHE features, we should expect OHE features to be sparser. Verify this hypothesis by computing the average sparsity of the OHE and the hashed training datasets.\n",
    "\n",
    "Note that if you have a `SparseVector` named `sparse`, calling `len(sparse)` returns the total number of features, not the number features with entries.  `SparseVector` objects have the attributes `indices` and `values` that contain information about which features are nonzero.  Continuing with our example, these can be accessed using `sparse.indices` and `sparse.values`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare, we can first see the indices of hash function feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1305  2883  3807  4814  4866  4913  6952  7117  9985 10316 11512 11722\n",
      " 12365 13893 14735 15816 16198 17761 19274 21604 22256 22563 22785 24855\n",
      " 25202 25533 25721 26487 26656 27668 28211 29152 29402 29873 30039 31484\n",
      " 32493 32708]\n"
     ]
    }
   ],
   "source": [
    "print hashTrainData.take(1)[0].features.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the indices of the OHE feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   382   3101   6842   8311   8911  11887  12893  16211  17631  18646\n",
      "  23513  29366  33157  39536  55820  61797  81485  82753  93671  96986\n",
      " 109720 110662 112139 120263 128571 132400 132805 140595 160666 185457\n",
      " 190322 191105 195902 202638 204242 206037 222753 225966 229941]\n"
     ]
    }
   ],
   "source": [
    "print OHETrainData.take(1)[0].features.indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the sample comparison, we can see using hash function, we can even reduce the feature dimension. In the followings, we compute the sparsity, and compare these feature representations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from operator import add\n",
    "def computeSparsity(data, d, n):\n",
    "    \"\"\"Calculates the average sparsity for the features in an RDD of LabeledPoints.\n",
    "    Args:\n",
    "        data (RDD of LabeledPoint): The LabeledPoints to use in the sparsity calculation.\n",
    "        d (int): The total number of features.\n",
    "        n (int): The number of observations in the RDD.\n",
    "    Returns:\n",
    "        float: The average of the ratio of features in a point to total features.\n",
    "    \"\"\"\n",
    "    '''or return data.map(lambda x: len(x.features.indices)).reduce(add)/float(n)/float(d) '''\n",
    "    return data.map(lambda x: len(x.features.indices)).sum()/float(n)/float(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average OHE Sparsity: 1.6717677e-04\n",
      "Average Hash Sparsity: 1.1805561e-03\n"
     ]
    }
   ],
   "source": [
    "averageSparsityHash = computeSparsity(hashTrainData, numBucketsCTR, nTrain)\n",
    "averageSparsityOHE = computeSparsity(OHETrainData, numCtrOHEFeats, nTrain)\n",
    "\n",
    "print 'Average OHE Sparsity: {0:.7e}'.format(averageSparsityOHE)\n",
    "print 'Average Hash Sparsity: {0:.7e}'.format(averageSparsityHash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 5.3: Logistic model with hashed features **\n",
    "Now let's train a logistic regression model using the hashed features. Run a grid search to find suitable hyperparameters for the hashed features, evaluating via log loss on the validation data. Note: This may take a few minutes to run. Use `1` and `10` for `stepSizes` and `1e-6` and `1e-3` for `regParams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numIters = 500\n",
    "regType = 'l2'\n",
    "includeIntercept = True\n",
    "\n",
    "# Initialize variables using values from initial model training\n",
    "bestModel = None\n",
    "bestLogLoss = 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tstepSize = 1.0, regParam = 1e-06: logloss = 0.470\n",
      "\tstepSize = 1.0, regParam = 1e-03: logloss = 0.470\n",
      "\tstepSize = 10.0, regParam = 1e-06: logloss = 0.448\n",
      "\tstepSize = 10.0, regParam = 1e-03: logloss = 0.450\n",
      "Hashed Features Validation Logloss:\n",
      "\tBaseline = 0.527\n",
      "\tLogReg = 0.448\n"
     ]
    }
   ],
   "source": [
    "# TODO: Replace <FILL IN> with appropriate code\n",
    "stepSizes = [1,10]\n",
    "regParams = [1e-6, 1e-3]\n",
    "for stepSize in stepSizes:\n",
    "    for regParam in regParams: \n",
    "        model = (LogisticRegressionWithSGD\n",
    "                 .train(hashTrainData, numIters, stepSize, regParam=regParam, regType=regType,\n",
    "                        intercept=includeIntercept))\n",
    "        logLossVa = evaluateResults(model, hashValidationData)\n",
    "        print ('\\tstepSize = {0:.1f}, regParam = {1:.0e}: logloss = {2:.3f}'\n",
    "               .format(stepSize, regParam, logLossVa))\n",
    "        if (logLossVa < bestLogLoss):\n",
    "            bestModel = model\n",
    "            bestLogLoss = logLossVa\n",
    "\n",
    "print ('Hashed Features Validation Logloss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(logLossValBase, bestLogLoss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best perform is to use stepSize = 10 and regParam = 1e-6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ** Sec. 5.4: Evaluate on the test set **\n",
    "Finally, evaluate the best model from Sec. 5.4 on the test set.  Compare the resulting log loss with the baseline log loss on the test set, which can be computed in the same way that the validation log loss was computed in Sec. 4.6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bestModel = (LogisticRegressionWithSGD\n",
    "                 .train(hashTrainData, iterations=500, step=10, regParam=1e-6, regType='l2',\n",
    "                        intercept=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hashed Features Test Log Loss:\n",
      "\tBaseline = 0.537\n",
      "\tLogReg = 0.456\n"
     ]
    }
   ],
   "source": [
    "# Log loss for the best model from Sec. 5.4:\n",
    "logLossTest = evaluateResults(bestModel, hashTestData)\n",
    "\n",
    "# Log loss for the baseline model:\n",
    "classOneFracTest = hashTestData.filter(lambda x: x.label==1).count()/float(hashTestData.count())\n",
    "logLossTestBaseline = hashTestData.map(lambda x: computeLogLoss(classOneFracTest, x.label)).mean()\n",
    "\n",
    "print ('Hashed Features Test Log Loss:\\n\\tBaseline = {0:.3f}\\n\\tLogReg = {1:.3f}'\n",
    "       .format(logLossTestBaseline, logLossTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sec. 5.5: Performance comparison using OHE and Hash feature reps**\n",
    "We can see using hash function to represent features gives slightly better performance than using OHE features (could be subject to some numeric errors). The reason may be less fetaures, the gradient descent is more efficient. But roughly speaking, they are similar.\n",
    "\n",
    "#### **(5.5a) Validation data**\n",
    "+ reg     |   logloss(OHE)  |  logloss(hash)\n",
    "+ 1e-06   |  0.456956712744 |   0.448\n",
    "\n",
    "#### **(5.5b) Test data**\n",
    "+ reg     |   logloss(OHE)  |  logloss(hash)\n",
    "+ 1e-06   |  0.464431773688 |   0.456"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sec. 6: Other Classifiers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sec. 6.1: Naive Bayes Classifier**\n",
    "\n",
    "The MLlib also has [Naive Bayes](http://spark.apache.org/docs/latest/mllib-naive-bayes.html) classifier. Here we focus on using the hash feature data. First we train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "nb = NaiveBayes.train(hashTrainData, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Naive Bayes classifier is not determined by decreasing loss function. So we cannot compute the logloss for the NB model. Instead, we compute the accuracy how many observations we predicted the same outcome as the label on validation and test datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(6.1a) Accuracy for Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.717518610422\n",
      "0.719093269423\n"
     ]
    }
   ],
   "source": [
    "# Make prediction and test accuracy for Naive Bayes classifier.\n",
    "predictionAndLabel = hashValidationData.map(lambda p: (nb.predict(p.features), p.label))\n",
    "print 1.0 * predictionAndLabel.filter(lambda (x, v): x == v).count() / nVal\n",
    "\n",
    "predictionAndLabel = hashTestData.map(lambda p: (nb.predict(p.features), p.label))\n",
    "print 1.0 * predictionAndLabel.filter(lambda (x, v): x == v).count() / nTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **(6.1b) Accuracy for logistic regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.794441687345\n",
      "0.795985620132\n"
     ]
    }
   ],
   "source": [
    "# Make prediction and test accuracy for logistic reg classifier.\n",
    "predictionAndLabel = hashValidationData.map(lambda p: (bestModel.predict(p.features), p.label))\n",
    "print 1.0 * predictionAndLabel.filter(lambda (x, v): x == v).count() / nVal\n",
    "\n",
    "predictionAndLabel = hashTestData.map(lambda p: (bestModel.predict(p.features), p.label))\n",
    "print 1.0 * predictionAndLabel.filter(lambda (x, v): x == v).count() / nTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can slight have a conclusion: **Logistic Regression has better accuracy than Naive Bayes!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sec. 6.2: Decision Trees model (not working)**\n",
    "\n",
    "The [decision tree model](http://spark.apache.org/docs/latest/mllib-naive-bayes.html) does not work here. The reason could be too many features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "DT = DecisionTree.trainClassifier(hashTrainData, 2, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
